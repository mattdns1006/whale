{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os, sys, glob\n",
    "from tqdm import tqdm\n",
    "from model import model1, model2\n",
    "sys.path.insert(0,\"/home/msmith/misc/py/\")\n",
    "from performance import Performance\n",
    "from hStackBatch import hStackBatch\n",
    "from loadData import loadData\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams[\"figure.figsize\"] = 20, 10\n",
    "import pickle\n",
    "\n",
    "\n",
    "    \n",
    "class Label2Name():\n",
    "    def __init__(self):\n",
    "        self.whaleDict = pickle.load(open(\"encoding.p\",\"rb\"))\n",
    "    def whaleName(self,searchLabel):\n",
    "        for whaleName, label in self.whaleDict.iteritems():\n",
    "            if label == searchLabel:\n",
    "                return whaleName.split(\"_\")[1]\n",
    "    def displayBatch(self,x_,y_,yPred_):\n",
    "        try:\n",
    "            x_ *= 255.0\n",
    "            bs = x_.shape[0]\n",
    "            x_ = x_.astype(np.uint8)[:,:,:,::-1]\n",
    "            fig = plt.figure(figsize=(40,20))\n",
    "            idx = 0\n",
    "            for i in range(1,bs+1):\n",
    "                ax = fig.add_subplot(1,bs+1,i)\n",
    "                ax.set_xticklabels([])\n",
    "                ax.set_yticklabels([])\n",
    "                plt.imshow(x_[idx])\n",
    "                prediction = self.whaleName(yPred_.argmax(1)[idx])\n",
    "                truth = self.whaleName(y_.argmax(1)[idx])\n",
    "                ax.set_title(\"Truth = {0}, Pred = {1}, ()\".format(truth,prediction))\n",
    "                idx +=1\n",
    "            plt.show()\n",
    "        except IndexError:\n",
    "            print(\"OOB\")\n",
    "\n",
    "def varSummary(var):\n",
    "    with tf.name_scope(\"summary\"):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar(\"mean\",var)\n",
    "        tf.summary.histogram(\"mean\",var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    label2Name =Label2Name()\n",
    "    batchSize  = 10\n",
    "    batchCapacity = 40\n",
    "    nThreads = 32\n",
    "\n",
    "    ## HyperParameter defaults\n",
    "    h, w, c = 300, 300, 3\n",
    "    nClasses = 447\n",
    "    inDims = [None,h,w,c]\n",
    "    nFeatsInit = 32\n",
    "    nFeatsInc = 16\n",
    "    #keepProb = 0.9 # dropout\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "    load = 0\n",
    "    display = 1\n",
    "    disFreq = 400\n",
    "    lr = 1e-3\n",
    "    nEpochs = 40\n",
    "    trainAll = False\n",
    "        \n",
    "    def nodes(trainOrTest):\n",
    "        assert trainOrTest in [\"train\",\"test\"], \"Please specify either 'train' or 'test.\"\n",
    "        if trainOrTest == \"train\":\n",
    "            csvPath = \"testCV.csv\"\n",
    "            shuffle = True\n",
    "            keepProb = 0.5\n",
    "            is_training=True\n",
    "        else:\n",
    "            csvPath = \"testCV.csv\"\n",
    "            shuffle = False\n",
    "            keepProb = 1.0\n",
    "            is_training = False\n",
    "        x, y, yPaths = loadData(csvPath,shape=[h,w,c],batchSize=batchSize,batchCapacity=batchCapacity,nThreads=nThreads,shuffle=shuffle)\n",
    "        # Define placeholders and model\n",
    "        yPred = model1(x,inDims=inDims,nClasses=nClasses,nFeatsInit=nFeatsInit,nFeatsInc=nFeatsInc,keepProb=keepProb,is_training=is_training) # model\n",
    "        with tf.variable_scope(\"performance\"):\n",
    "            with tf.variable_scope(\"ce\"):\n",
    "                ce = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(yPred,y))\n",
    "            with tf.variable_scope(\"correct\"):\n",
    "                correct = tf.equal(tf.argmax(yPred,1), tf.argmax(y,1))\n",
    "            with tf.variable_scope(\"accuracy\"):\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "            trainStep = None\n",
    "        if trainOrTest == \"train\":\n",
    "            learningRate = tf.placeholder(tf.float32)\n",
    "            trainStep = tf.train.AdamOptimizer(learningRate).minimize(ce)\n",
    "            return x, y, yPaths, yPred, ce, correct, accuracy, trainStep, learningRate\n",
    "        else:\n",
    "            return x, y, yPaths, yPred, ce, correct, accuracy, _, _\n",
    "    \n",
    "    specification = \"{0}_{1}_{2}_{3}_{4}_{5}/\".format(batchSize,lr,h,w,nFeatsInit,nFeatsInc)\n",
    "    modelFolder = \"models/model_{0}\".format(specification)\n",
    "    if not os.path.exists(modelFolder):\n",
    "        os.mkdir(modelFolder)\n",
    "    modelName = modelFolder + \"model.tf\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 40\n",
      "Shuffling csv\n",
      "(10, 300, 300, 3)\n",
      "(10, 150, 150, 32)\n",
      "(10, 75, 75, 48)\n",
      "(10, 38, 38, 64)\n",
      "(10, 19, 19, 80)\n",
      "(10, 10, 10, 96)\n",
      "(10, 5, 5, 112)\n",
      "(10, 3, 3, 128)\n",
      "(10, 1152)\n",
      "(10, 128)\n",
      "(10, 447)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    count = 0\n",
    "    for epoch in xrange(nEpochs):\n",
    "        clear_output()\n",
    "        print(\"Epoch {0} of {1}\".format(epoch,nEpochs))\n",
    "        for trTe in [\"train\"]:\n",
    "            if epoch > 0:\n",
    "                load = 1 # Must have a model to load by 2nd epoch... so load it !\n",
    "                tf.reset_default_graph()\n",
    "            x, y, yPaths, yPred, ce, correct, accuracy, trainStep, learningRate = nodes(trTe)\n",
    "            [varSummary(var) for var in [ce,accuracy]] # Summaries\n",
    "            merged = tf.summary.merge_all()\n",
    "            saver = tf.train.Saver()\n",
    "            with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "                if load == 1:\n",
    "                    print(\"Loading {0}\".format(modelName))\n",
    "                    saver.restore(sess,modelName)\n",
    "                else:\n",
    "                    print(\"Initializing variables\".format(modelName))\n",
    "                    tf.global_variables_initializer().run()\n",
    "                tf.local_variables_initializer().run()\n",
    "                    \n",
    "                writer = tf.summary.FileWriter(\"summary/{0}/{1}\".format(specification,trTe),sess.graph)\n",
    "                coord = tf.train.Coordinator()\n",
    "                threads = tf.train.start_queue_runners(sess=sess,coord=coord)    \n",
    "                try:\n",
    "                    while True:      \n",
    "                        if trTe == \"train\":\n",
    "                            _,summary,x_, y_,yPred_,yPaths_ = sess.run([trainStep,merged,x,y,yPred,yPaths],feed_dict={learningRate:lr})\n",
    "                            writer.add_summary(summary,count)\n",
    "                            count += 1\n",
    "                            if np.random.uniform() < 0.01:\n",
    "                                label2Name.displayBatch(x_,yPred_=yPred_,y_=y_)\n",
    "                        if coord.should_stop():\n",
    "                            break\n",
    "                except Exception, e:\n",
    "                    coord.request_stop(e)\n",
    "                finally:\n",
    "                    coord.request_stop()\n",
    "                    coord.join(threads)\n",
    "                    \n",
    "                print(\"Saving {0}\".format(modelName))\n",
    "                saver.save(sess,modelName)\n",
    "                sess.close()\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
