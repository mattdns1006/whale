{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os, sys, glob\n",
    "from tqdm import tqdm\n",
    "from model import model1, model2\n",
    "sys.path.insert(0,\"/home/msmith/misc/py/\")\n",
    "from performance import Performance\n",
    "from hStackBatch import hStackBatch\n",
    "from loadData import loadData\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams[\"figure.figsize\"] = 20, 10\n",
    "\n",
    "def displayBatch(X,names,predictions):\n",
    "    try:\n",
    "        #X,Y = XY\n",
    "        #names = train.decodeToName(Y)\n",
    "        X *= 255.0\n",
    "        bs = X.shape[0]\n",
    "        X = X.astype(np.uint8)[:,:,:,::-1]\n",
    "        fig = plt.figure(figsize=(40,20))\n",
    "        idx = 0\n",
    "        for i in range(1,bs+1):\n",
    "            ax = fig.add_subplot(1,bs+1,i)\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            plt.imshow(X[idx])\n",
    "            if names[idx] == predictions[idx]:\n",
    "                correct = 1\n",
    "            else:\n",
    "                correct = 0\n",
    "            ax.set_title(\"Truth = {0}, Pred = {1}, ({2})\".format(names[idx],predictions[idx],correct))\n",
    "            idx +=1\n",
    "        plt.show()\n",
    "    except IndexError:\n",
    "        print(\"OOB\")\n",
    "        \n",
    "def decodeLabel(label):\n",
    "    '''\n",
    "    Takes whale label eg. label = 125.\n",
    "    Returns: whale name eg. whale_27860\n",
    "    '''\n",
    "    \n",
    "    whalePath = df.loc[df.label == label].fullPath\n",
    "    whaleName = whalePath.iloc[0].split(\"/\")[2].replace(\"whale_\",\"\")\n",
    "    return whaleName\n",
    "decodeLabel = np.vectorize(decodeLabel)\n",
    "\n",
    "def varSummary(var):\n",
    "    with tf.name_scope(\"summary\"):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar(\"mean\",var)\n",
    "        tf.summary.histogram(\"mean\",var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    batchSize  = 10\n",
    "    batchCapacity = 40\n",
    "    nThreads = 32\n",
    "\n",
    "    ## HyperParameter defaults\n",
    "    h, w, c = 500, 500, 3\n",
    "    nClasses = 447\n",
    "    inDims = [None,h,w,c]\n",
    "    nFeatsInit = 32\n",
    "    nFeatsInc = 32\n",
    "    #keepProb = 0.9 # dropout\n",
    "   \n",
    "    load = 0\n",
    "    display = 1\n",
    "    disFreq = 400\n",
    "    lr = 3e-4\n",
    "    nEpochs = 5\n",
    "    trainAll = False\n",
    "        \n",
    "    def nodes(trainOrTest):\n",
    "        assert trainOrTest in [\"train\",\"test\"], \"Please specify either 'train' or 'test.\"\n",
    "        if trainOrTest == \"train\":\n",
    "            csvPath = \"trainCV.csv\"\n",
    "            shuffle = True\n",
    "            keepProb = 0.5\n",
    "            is_training=True\n",
    "        else:\n",
    "            csvPath = \"testCV.csv\"\n",
    "            shuffle = False\n",
    "            keepProb = 1.0\n",
    "            is_training = False\n",
    "        x, y, yPaths = loadData(csvPath,shape=[h,w,c],batchSize=batchSize,batchCapacity=batchCapacity,nThreads=nThreads,shuffle=shuffle)\n",
    "        # Define placeholders and model\n",
    "        yPred = model1(x,inDims=inDims,nClasses=nClasses,nFeatsInit=nFeatsInit,nFeatsInc=nFeatsInc,keepProb=keepProb,training=is_training) # model\n",
    "        ce = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(yPred,y))\n",
    "        \n",
    "        correct = tf.equal(tf.argmax(yPred,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        trainStep = None\n",
    "        if trainOrTest == \"train\":\n",
    "            learningRate = tf.placeholder(tf.float32)\n",
    "            trainStep = tf.train.AdamOptimizer(learningRate).minimize(ce)\n",
    "            return x, y, yPaths, yPred, ce, correct, accuracy, trainStep, learningRate\n",
    "        else:\n",
    "            return x, y, yPaths, yPred, ce, correct, accuracy, _, _\n",
    "    \n",
    "    modelName = \"models/model2.tf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling csv\n",
      "(10, 500, 500, 3)\n",
      "(10, 250, 250, 32)\n",
      "(10, 125, 125, 64)\n",
      "(10, 63, 63, 96)\n",
      "(10, 32, 32, 128)\n",
      "(10, 16, 16, 160)\n",
      "(10, 8, 8, 192)\n",
      "(10, 4, 4, 224)\n",
      "(10, 2, 2, 256)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for epoch in xrange(1):\n",
    "        for trTe in [\"train\"]:\n",
    "            if epoch > 0:\n",
    "                load = 1 # Must have a model to load by 2nd epoch... so load it !\n",
    "                tf.reset_default_graph()\n",
    "            x, y, yPaths, yPred, ce, correct, accuracy, trainStep, learningRate = nodes(trTe)\n",
    "            [varSummary(x) for x in [ce,accuracy]] # Summaries\n",
    "            merged = tf.summary.merge_all()\n",
    "            saver = tf.train.Saver()\n",
    "            with tf.Session() as sess:\n",
    "                if load == 1:\n",
    "                    saver.restore(sess,modelName)\n",
    "                writer = tf.summary.FileWriter(\"summary/{0}\".format(trTe),sess.graph)\n",
    "                tf.global_variables_initializer().run()\n",
    "                tf.local_variables_initializer().run()\n",
    "                coord = tf.train.Coordinator()\n",
    "                threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "                count = 0\n",
    "                try:\n",
    "                    while True:      \n",
    "                        if trTe == \"train\":\n",
    "                            _,summary = sess.run([trainStep,merged],feed_dict={learningRate:lr})\n",
    "                            writer.add_summary(summary,count)\n",
    "                            count += 1\n",
    "                        if coord.should_stop():\n",
    "                            break\n",
    "                except Exception, e:\n",
    "                    coord.request_stop(e)\n",
    "                finally:\n",
    "                    coord.request_stop()\n",
    "                    coord.join(threads)\n",
    "                saver.save(sess,modelName)\n",
    "                sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
